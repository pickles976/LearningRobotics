{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from scipy import ndimage\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:04<00:00,  1.65it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00,  7.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# takes all images and convert them to grayscale. \n",
    "# return a dictionary that holds all images category by category. \n",
    "def load_images_from_folder(folder):\n",
    "    images = {}\n",
    "    for filename in tqdm(os.listdir(folder)):\n",
    "        category = []\n",
    "        path = folder + \"/\" + filename\n",
    "        for cat in os.listdir(path):\n",
    "            img = cv2.imread(path + \"/\" + cat,0)\n",
    "            #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            if img is not None:\n",
    "                category.append(img)\n",
    "        images[filename] = category\n",
    "    return images\n",
    "\n",
    "# images = load_images_from_folder(\"data\")\n",
    "images = load_images_from_folder('dataset/train')  # take all images category by category \n",
    "test = load_images_from_folder(\"dataset/test\") # take test images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:10<00:00,  1.48s/it]\n",
      "100%|██████████| 7/7 [00:02<00:00,  3.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# Creates descriptors using sift \n",
    "# Takes one parameter that is images dictionary\n",
    "# Return an array whose first index holds the decriptor_list without an order\n",
    "# And the second index holds the sift_vectors dictionary which holds the descriptors but this is seperated class by class\n",
    "def orb_features(images):\n",
    "    orb_vectors = {}\n",
    "    descriptor_list = []\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    # Loop over classes\n",
    "    for key,value in tqdm(images.items()):\n",
    "        features = []\n",
    "        for img in value:\n",
    "            kp, des = orb.detectAndCompute(img,None)\n",
    "\n",
    "            if des is not None:\n",
    "                descriptor_list.extend(des)\n",
    "                features.append(des)\n",
    "        orb_vectors[key] = features\n",
    "    return [descriptor_list, orb_vectors]\n",
    "\n",
    "# descriptor list is unordered one, sift features that is seperated class by class for train data\n",
    "descriptor_list, all_bovw_feature = orb_features(images) \n",
    "# Takes the sift features that is seperated class by class for test data\n",
    "test_bovw_feature = orb_features(test)[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 32)\n",
      "[134.47598  110.96585   86.05241  173.00012   67.23574  172.29462\n",
      "  70.49426   89.048256 156.54669   85.549286 180.01643  175.21315\n",
      " 125.39979  178.02411   96.57973  164.29842  185.2338   159.26035\n",
      " 217.13612  144.36104   79.92036   67.27581  143.49489  186.40923\n",
      " 180.09035  199.6814    90.15073  174.53725   68.434395  66.42967\n",
      "  63.082005  84.7094  ]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# A k-means clustering algorithm who takes 2 parameter which is number \n",
    "# of cluster(k) and the other is descriptors list(unordered 1d array)\n",
    "# Returns an array that holds central points.\n",
    "def kmeans(k, descriptor_list):\n",
    "    # kmeans = KMeans(n_clusters = k, n_init=10, max_iter=50)\n",
    "    kmeans = MiniBatchKMeans(n_clusters=k, n_init=10)\n",
    "    kmeans.fit(descriptor_list)\n",
    "    visual_words = kmeans.cluster_centers_ \n",
    "    return visual_words\n",
    "    \n",
    "# Takes the central points which is visual words    \n",
    "descriptor_list = np.stack(descriptor_list, dtype=np.float32)\n",
    "visual_words = kmeans(150, descriptor_list) \n",
    "print(visual_words.shape)\n",
    "print(visual_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying training data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [01:15<07:35, 75.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "green: 133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [01:45<04:02, 48.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house_indoor: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [02:56<03:55, 58.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sea: 141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4/7 [03:46<02:46, 55.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house_building: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [04:56<02:01, 60.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city: 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 6/7 [06:04<01:03, 63.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face: 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [07:13<00:00, 61.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "office: 140\n",
      "Classifying testing data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [00:13<01:22, 13.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "green: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [00:28<01:11, 14.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house_indoor: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [00:42<00:55, 13.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sea: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4/7 [00:55<00:40, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house_building: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [01:09<00:27, 13.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 6/7 [01:23<00:13, 14.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [01:38<00:00, 14.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "office: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def closest_centroid(x, centroids):\n",
    "    \"\"\"Finds and returns the index of the closest centroid for a given vector x\"\"\"\n",
    "    distances = np.empty(len(centroids))\n",
    "    for i in range(len(centroids)):\n",
    "        distances[i] = distance.euclidean(centroids[i], x)\n",
    "    return np.argmin(distances) # return the index of the lowest distance\n",
    "\n",
    "# Takes 2 parameters. The first one is a dictionary that holds the descriptors that are separated class by class \n",
    "# And the second parameter is an array that holds the central points (visual words) of the k means clustering\n",
    "# Returns a dictionary that holds the histograms for each images that are separated class by class. \n",
    "def image_class(all_bovw, centers):\n",
    "    dict_feature = {}\n",
    "    for key,value in tqdm(all_bovw.items()):\n",
    "        category = []\n",
    "        for img in value:\n",
    "            histogram = np.zeros(len(centers))\n",
    "            for each_feature in img:\n",
    "                # ind = np.where(centers == each_feature)[0] # \n",
    "                ind = closest_centroid(each_feature, centers)\n",
    "                histogram[ind] += 1\n",
    "            category.append(histogram)\n",
    "        dict_feature[key] = category\n",
    "        print(f\"{key}: {len(category)}\")\n",
    "    return dict_feature\n",
    "\n",
    "# Creates histograms for train data    \n",
    "print(\"Classifying training data\")\n",
    "bovw_train = image_class(all_bovw_feature, visual_words) \n",
    "# Creates histograms for test data\n",
    "print(\"Classifying testing data\")\n",
    "bovw_test = image_class(test_bovw_feature, visual_words) \n",
    "\n",
    "## TODO: Should probably Pickle this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 47.14285714285714%\n",
      "{'green': [13, 30], 'house_indoor': [2, 30], 'sea': [15, 30], 'house_building': [6, 30], 'city': [18, 30], 'face': [26, 30], 'office': [19, 30]}\n"
     ]
    }
   ],
   "source": [
    "# 1-NN algorithm. We use this for predict the class of test images.\n",
    "# Takes 2 parameters. images is the feature vectors of train images and tests is the feature vectors of test images\n",
    "# Returns an array that holds number of test images, number of correctly predicted images and records of class based images respectively\n",
    "def knn(images, tests):\n",
    "    num_test = 0\n",
    "    correct_predict = 0\n",
    "    class_based = {}\n",
    "    \n",
    "    for test_key, test_val in tests.items():\n",
    "        class_based[test_key] = [0, 0] # [correct, all]\n",
    "        \n",
    "        for tst in test_val:\n",
    "            predict_start = 0\n",
    "            minimum = 0\n",
    "            key = \"a\" #predicted\n",
    "\n",
    "            # Find the closest match\n",
    "            for train_key, train_val in images.items():\n",
    "                for train in train_val:\n",
    "                    if(predict_start == 0):\n",
    "                        minimum = distance.euclidean(tst, train)\n",
    "                        #minimum = L1_dist(tst,train)\n",
    "                        key = train_key\n",
    "                        predict_start += 1\n",
    "                    else:\n",
    "                        dist = distance.euclidean(tst, train)\n",
    "                        #dist = L1_dist(tst,train)\n",
    "                        if(dist < minimum):\n",
    "                            minimum = dist\n",
    "                            key = train_key\n",
    "            \n",
    "            if(test_key == key):\n",
    "                correct_predict += 1\n",
    "                class_based[test_key][0] += 1\n",
    "            num_test += 1\n",
    "            class_based[test_key][1] += 1\n",
    "\n",
    "    return [num_test, correct_predict, class_based]\n",
    "    \n",
    "# Call the knn function    \n",
    "test, correct, classes = knn(bovw_train, bovw_test) \n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: %47.14285714285714\n",
      "\n",
      "Class based accuracies: \n",
      "\n",
      "green : %43.333333333333336\n",
      "house_indoor : %6.666666666666667\n",
      "sea : %50.0\n",
      "house_building : %20.0\n",
      "city : %60.0\n",
      "face : %86.66666666666667\n",
      "office : %63.33333333333333\n"
     ]
    }
   ],
   "source": [
    "# Calculates the average accuracy and class based accuracies.  \n",
    "def accuracy(results):\n",
    "    avg_accuracy = (results[1] / results[0]) * 100\n",
    "    print(\"Average accuracy: %\" + str(avg_accuracy))\n",
    "    print(\"\\nClass based accuracies: \\n\")\n",
    "    for key,value in results[2].items():\n",
    "        acc = (value[0] / value[1]) * 100\n",
    "        print(key + \" : %\" + str(acc))\n",
    "        \n",
    "# Calculates the accuracies and write the results to the console.       \n",
    "accuracy((test, correct, classes)) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
