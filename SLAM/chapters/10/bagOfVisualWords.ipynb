{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from scipy import ndimage\n",
    "from scipy.spatial import distance\n",
    "# from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes all images and convert them to grayscale. \n",
    "# return a dictionary that holds all images category by category. \n",
    "def load_images_from_folder(folder):\n",
    "    images = {}\n",
    "    for filename in os.listdir(folder):\n",
    "        category = []\n",
    "        path = folder + \"/\" + filename\n",
    "        for cat in os.listdir(path):\n",
    "            img = cv2.imread(path + \"/\" + cat,0)\n",
    "            #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            if img is not None:\n",
    "                category.append(img)\n",
    "        images[filename] = category\n",
    "    return images\n",
    "\n",
    "# images = load_images_from_folder(\"data\")\n",
    "images = load_images_from_folder('dataset/train')  # take all images category by category \n",
    "test = load_images_from_folder(\"dataset/test\") # take test images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates descriptors using sift \n",
    "# Takes one parameter that is images dictionary\n",
    "# Return an array whose first index holds the decriptor_list without an order\n",
    "# And the second index holds the sift_vectors dictionary which holds the descriptors but this is seperated class by class\n",
    "def orb_features(images):\n",
    "    orb_vectors = {}\n",
    "    descriptor_list = []\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    # Loop over classes\n",
    "    for key,value in images.items():\n",
    "        features = []\n",
    "        for img in value:\n",
    "            kp, des = orb.detectAndCompute(img,None)\n",
    "\n",
    "            if des is not None:\n",
    "                descriptor_list.extend(des)\n",
    "                features.append(des)\n",
    "        orb_vectors[key] = features\n",
    "    return [descriptor_list, orb_vectors]\n",
    "\n",
    "# descriptor list is unordered one, sift features that is seperated class by class for train data\n",
    "descriptor_list, all_bovw_feature = orb_features(images) \n",
    "# Takes the sift features that is seperated class by class for test data\n",
    "test_bovw_feature = orb_features(test)[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# A k-means clustering algorithm who takes 2 parameter which is number \n",
    "# of cluster(k) and the other is descriptors list(unordered 1d array)\n",
    "# Returns an array that holds central points.\n",
    "def kmeans(k, descriptor_list):\n",
    "    kmeans = KMeans(n_clusters = k, n_init=10, max_iter=50)\n",
    "    # kmeans = MiniBatchKMeans(n_clusters=k, n_init=10)\n",
    "    kmeans.fit(descriptor_list)\n",
    "    visual_words = kmeans.cluster_centers_ \n",
    "    return visual_words\n",
    "    \n",
    "# Takes the central points which is visual words    \n",
    "visual_words = kmeans(150, descriptor_list) \n",
    "print(len(visual_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes 2 parameters. The first one is a dictionary that holds the descriptors that are separated class by class \n",
    "# And the second parameter is an array that holds the central points (visual words) of the k means clustering\n",
    "# Returns a dictionary that holds the histograms for each images that are separated class by class. \n",
    "def image_class(all_bovw, centers):\n",
    "    dict_feature = {}\n",
    "    for key,value in all_bovw.items():\n",
    "        category = []\n",
    "        for img in value:\n",
    "            histogram = np.zeros(len(centers))\n",
    "            for each_feature in img:\n",
    "                ind = np.where(centers == each_feature)[0] # \n",
    "                histogram[ind] += 1\n",
    "            category.append(histogram)\n",
    "        dict_feature[key] = category\n",
    "    return dict_feature\n",
    "    \n",
    "# Creates histograms for train data    \n",
    "bovw_train = image_class(all_bovw_feature, visual_words) \n",
    "# Creates histograms for test data\n",
    "bovw_test = image_class(test_bovw_feature, visual_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-NN algorithm. We use this for predict the class of test images.\n",
    "# Takes 2 parameters. images is the feature vectors of train images and tests is the feature vectors of test images\n",
    "# Returns an array that holds number of test images, number of correctly predicted images and records of class based images respectively\n",
    "def knn(images, tests):\n",
    "    num_test = 0\n",
    "    correct_predict = 0\n",
    "    class_based = {}\n",
    "    \n",
    "    for test_key, test_val in tests.items():\n",
    "        class_based[test_key] = [0, 0] # [correct, all]\n",
    "        for tst in test_val:\n",
    "            predict_start = 0\n",
    "            #print(test_key)\n",
    "            minimum = 0\n",
    "            key = \"a\" #predicted\n",
    "            for train_key, train_val in images.items():\n",
    "                for train in train_val:\n",
    "                    if(predict_start == 0):\n",
    "                        minimum = distance.euclidean(tst, train)\n",
    "                        #minimum = L1_dist(tst,train)\n",
    "                        key = train_key\n",
    "                        predict_start += 1\n",
    "                    else:\n",
    "                        dist = distance.euclidean(tst, train)\n",
    "                        #dist = L1_dist(tst,train)\n",
    "                        if(dist < minimum):\n",
    "                            minimum = dist\n",
    "                            key = train_key\n",
    "            \n",
    "            if(test_key == key):\n",
    "                correct_predict += 1\n",
    "                class_based[test_key][0] += 1\n",
    "            num_test += 1\n",
    "            class_based[test_key][1] += 1\n",
    "            #print(minimum)\n",
    "    return [num_test, correct_predict, class_based]\n",
    "    \n",
    "# Call the knn function    \n",
    "results_bowl = knn(bovw_train, bovw_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: %14.285714285714285\n",
      "\n",
      "Class based accuracies: \n",
      "\n",
      "green : %100.0\n",
      "house_indoor : %0.0\n",
      "sea : %0.0\n",
      "house_building : %0.0\n",
      "city : %0.0\n",
      "face : %0.0\n",
      "office : %0.0\n"
     ]
    }
   ],
   "source": [
    "# Calculates the average accuracy and class based accuracies.  \n",
    "def accuracy(results):\n",
    "    avg_accuracy = (results[1] / results[0]) * 100\n",
    "    print(\"Average accuracy: %\" + str(avg_accuracy))\n",
    "    print(\"\\nClass based accuracies: \\n\")\n",
    "    for key,value in results[2].items():\n",
    "        acc = (value[0] / value[1]) * 100\n",
    "        print(key + \" : %\" + str(acc))\n",
    "        \n",
    "# Calculates the accuracies and write the results to the console.       \n",
    "accuracy(results_bowl) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
