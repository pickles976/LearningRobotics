{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel2cam(p, K):\n",
    "    return np.array([(p[0] - K[0, 2]) / K[0, 0],\n",
    "                     (p[1] - K[1, 2]) / K[1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangulation(R, t, pts_1, pts_2):\n",
    "    T1 = np.eye(3, 4)\n",
    "    T2 = np.concatenate((R, t), axis=1)\n",
    "    pts_4d = cv2.triangulatePoints(T1, T2, pts_1, pts_2)\n",
    "    points = []\n",
    "    for i in range(pts_4d.shape[1]):\n",
    "        x = pts_4d[:, i]\n",
    "        p = np.array([[x[0]/x[3]], [x[1]/x[3]], [x[2]/x[3]]])\n",
    "        points.append(p)\n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFeatureMatches(img_1, img_2):\n",
    "\n",
    "    # Keypoints and their descriptors\n",
    "    keypoints_1, keypoints_2 = [], []\n",
    "    descriptors_1, descriptors_2 = [], []\n",
    "\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    keypoints_1, descriptors_1 = orb.detectAndCompute(img_1, None)\n",
    "    keypoints_2, descriptors_2 = orb.detectAndCompute(img_2, None)\n",
    "\n",
    "    matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "\n",
    "    matches = matcher.match(descriptors_1, descriptors_2)\n",
    "\n",
    "    # Sort and remove outliers\n",
    "    matches = sorted(matches, key = lambda x: x.distance)\n",
    "\n",
    "    min_dist = matches[0].distance\n",
    "    max_dist = matches[len(matches) - 1].distance\n",
    "\n",
    "    print(f\"Min dist: {min_dist}, Max dist: {max_dist}\")\n",
    "\n",
    "    good_matches = []\n",
    "\n",
    "    for i in range(descriptors_1.shape[0]):\n",
    "        if matches[i].distance <= max(2 * min_dist, 30.0):\n",
    "            good_matches.append(matches[i])\n",
    "\n",
    "    return keypoints_1, keypoints_2, good_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poseEstimation2d2d(key_points_1, key_points_2, matches):\n",
    "\n",
    "    # Convert the matching point to the form of Vector<Point2f>\n",
    "    points1, points2 = [], []\n",
    "\n",
    "    for i in range(len(matches)):\n",
    "        points1.append(key_points_1[matches[i].queryIdx].pt)\n",
    "        points2.append(key_points_2[matches[i].trainIdx].pt)\n",
    "\n",
    "    points1 = np.asarray(points1)\n",
    "    points2 = np.asarray(points2)\n",
    "\n",
    "    # Camera intrinsics\n",
    "    K = np.array([520.9, 0, 325.1, 0, 521.0, 249.7, 0, 0, 1]).reshape((3,3))\n",
    "\n",
    "    # calculate fundamental and essential matrix\n",
    "    fundamental_matrix, mask = cv2.findFundamentalMat(points1, points2, cv2.FM_8POINT)\n",
    "    print(f\"Fundamental matrix is: {fundamental_matrix}\")\n",
    "\n",
    "    essential_matrix, mask = cv2.findEssentialMat(points1, points2, K)\n",
    "    print(f\"Essential matrix is: {essential_matrix}\")\n",
    "\n",
    "    # Calculate homography matrix\n",
    "    homography_matrix = cv2.findHomography(points1, points2, cv2.RANSAC, 3)\n",
    "\n",
    "    pp = (325.1, 249.7)\n",
    "    focal = 521\n",
    "\n",
    "    # Recover rotation and translation from the essential matrix\n",
    "    return cv2.recoverPose(essential_matrix, points1, points2, K, focal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min dist: 4.0, Max dist: 94.0\n",
      "In total we have 79 feature points\n",
      "Fundamental matrix is: [[ 4.54443750e-06  1.33385558e-04 -1.79849925e-02]\n",
      " [-1.27565701e-04  2.26679480e-05 -1.41667843e-02]\n",
      " [ 1.81499464e-02  4.14605587e-03  1.00000000e+00]]\n",
      "Essential matrix is: [[-0.00216463  0.10709656  0.09820592]\n",
      " [-0.05307528  0.03076833 -0.69812107]\n",
      " [-0.05866729  0.69562566  0.02018955]]\n",
      "R: [[ 0.99530207 -0.05373494  0.08053783]\n",
      " [ 0.05062839  0.99791092  0.04013191]\n",
      " [-0.08252607 -0.03586588  0.99594332]]\n",
      "t: [[-0.9786534 ]\n",
      " [-0.13314121]\n",
      " [ 0.1565597 ]]\n",
      "t^R= \n",
      "[[ 0.          0.00841273 -0.0107229 ]\n",
      " [ 0.00792637 -0.          0.03927523]\n",
      " [-0.01098762  0.03510026  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "img_1 = cv2.imread(\"1.png\")\n",
    "img_2 = cv2.imread(\"2.png\")\n",
    "\n",
    "# Get matches and key points for images\n",
    "key_points_1, key_points_2, matches = findFeatureMatches(img_1, img_2)\n",
    "print(f\"In total we have {len(matches)} feature points\")\n",
    "\n",
    "_, R, t, mask = poseEstimation2d2d(key_points_1, key_points_2, matches)\n",
    "print(f\"R: {R}\")\n",
    "print(f\"t: {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t^R= \n",
      "[[ 0.          0.00841273 -0.0107229 ]\n",
      " [ 0.00792637 -0.          0.03927523]\n",
      " [-0.01098762  0.03510026  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Check E = t^R*scale\n",
    "t_x = np.cross(np.eye(3), t.transpose())\n",
    "print(f\"t^R= \\n{t_x*R}\")  # I guess this is scale simular to E\n",
    "\n",
    "# Check epipolar constraints (commented out)\n",
    "# Convert pixel coordinates to camera coordinates\n",
    "K = np.array([[520.9, 0, 325.1], [0, 521.0, 249.7], [0, 0, 1]])\n",
    "# These have to be 2xN numpy arrays\n",
    "pts_1 = np.empty((2, 0))\n",
    "pts_2 = np.empty((2,0))\n",
    "for m in matches:\n",
    "    pt1 = pixel2cam(key_points_1[m.queryIdx].pt, K)\n",
    "    # y1 = np.array([[pt1[0]], [pt1[1]], [1]])\n",
    "    pt2 = pixel2cam(key_points_2[m.trainIdx].pt, K)\n",
    "    # y2 = np.array([[pt2[0]], [pt2[1]], [1]])\n",
    "    # d = np.dot(np.dot(y2.transpose(), t_x), np.dot(R, y1))\n",
    "    # print(f\"epipolar constraint: {d}\")\n",
    "    pts_1 = np.hstack([pts_1, np.array(pt1).reshape(-1, 1)])\n",
    "    pts_2 = np.hstack([pts_2, np.array(pt2).reshape(-1, 1)])\n",
    "\n",
    "# Why does this work?\n",
    "points3D = triangulation(R, t, pts_1, pts_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_color(depth):\n",
    "    up_th = 11.7\n",
    "    low_th = 6.4\n",
    "    th_range = up_th - low_th\n",
    "    if depth > up_th:\n",
    "        depth = up_th\n",
    "    if depth < low_th:\n",
    "        depth = low_th\n",
    "    scaled_range = depth-low_th\n",
    "    color = tuple(int(x) for x in (255 * scaled_range/th_range, 0, 255 * (1 - scaled_range/th_range)))\n",
    "    return color\n",
    "\n",
    "\n",
    "# plot the points with color depth\n",
    "img1_plot = img_1.copy()\n",
    "img2_plot = img_2.copy()\n",
    "for i in range(len(matches)):\n",
    "    depth1 = points3D[i][2]\n",
    "    pix1 = tuple(int(x) for x in key_points_1[matches[i].queryIdx].pt)\n",
    "    pt1_cam = pixel2cam(key_points_1[matches[i].queryIdx].pt, K)\n",
    "    cv2.circle(img1_plot, pix1, 2, get_color(depth1), 2)\n",
    "    pt2_trans = R.dot(points3D[i]) + t\n",
    "    depth2 = pt2_trans[2]\n",
    "    pix2 = tuple(int(x) for x in key_points_2[matches[i].trainIdx].pt)\n",
    "    cv2.circle(img2_plot, pix2, 2, get_color(depth2), 2)\n",
    "cv2.imshow(\"img_1\", img1_plot)\n",
    "cv2.imshow(\"img_2\", img2_plot)\n",
    "cv2.waitKey()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
